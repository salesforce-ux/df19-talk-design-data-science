{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Designs Using Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QQe1V2WojX15"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import colorsys\n",
    "\n",
    "# data and numbers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns;\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import figure\n",
    "\n",
    "# machine learning\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import cluster, datasets, mixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display the first 5 lines of it\n",
    "df = pd.read_csv('fortune_500_h1.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Handle undefined or faulty data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove undefined and nan values\n",
    "df.replace('undefined', np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# dropping duplicate values\n",
    "df.drop_duplicates(subset=['name'], keep='first', inplace=True)\n",
    "\n",
    "\n",
    "# remove 'px' from the font size, then convert/round down to integer\n",
    "df['font-size'] = df['font-size'].apply(lambda v: v if isinstance(v,int) else int(float(v.replace('px', ''))) )\n",
    "\n",
    "# remove row if font-size is below 9 as we would expect valid headers to be larger than 9px\n",
    "df.drop(df[ df['font-size'] < 9 ].index, inplace=True)\n",
    "df.drop(df[ df['font-size'] > 100 ].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ensure data types are ones we can work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure our font weight is an integer\n",
    "df['font-weight'] = df['font-weight'].apply(int)\n",
    "\n",
    "\n",
    "# convert sector names to numbers and write to 'sector-codes' column\n",
    "df[\"sector\"] = df[\"sector\"].astype('category')\n",
    "df[\"sector-codes\"] = df['sector'].cat.codes\n",
    "\n",
    "\n",
    "# \"rgb(255,155,0)\" -> ['255','155','0'] \n",
    "split = lambda val: re.sub(r'(rgb|\\(|\\))', '', val).split(\",\")\n",
    "\n",
    "# ['255','155','bad'] -> [255,155,nan] \n",
    "parse = lambda val : int(val) if val.isdigit() else np.nan\n",
    "\n",
    "# [255,155,nan] -> nan or [255,155,0] -> [255,155,0]\n",
    "clean = lambda arr : np.nan if True in np.isnan(np.array(arr)) else arr\n",
    "\n",
    "# remove row if color is rgba instead of rgb\n",
    "df[~df['color'].str.contains(\"rgba\")]\n",
    "\n",
    "# convert 'rgb(r,g,b)' string to '[r,g,b]' list\n",
    "df[\"rgb\"] = df[\"color\"].apply(lambda val: clean( list( map( parse, split(val) ) ) ) )\n",
    "\n",
    "# remove row if color is invalid\n",
    "df.dropna(subset=['rgb'], inplace=True)\n",
    "\n",
    "# convert rgb to hsv colors so we have another representation to play around with\n",
    "df[\"hsv\"] = df[\"rgb\"].apply(lambda rgb: list(colorsys.rgb_to_hsv(rgb[0]/255., rgb[1]/255., rgb[2]/255.)) )\n",
    "\n",
    "# and put all the rgb/hsv into separate columns\n",
    "df[['h','s','v']] = df['hsv'].apply(pd.Series)\n",
    "df[['r','g','b']] = df['rgb'].apply(pd.Series)\n",
    "\n",
    "# save a hex representation of the color while we're at it\n",
    "df[\"hex\"] = df[\"rgb\"].apply(lambda rgb: \"#{:02x}{:02x}{:02x}\".format(rgb[0],rgb[1],rgb[2]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove columns we're not interested in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['backgroundColor', 'name', 'color'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out our cleaned up data frame\n",
    "#df = df.sort_values(by='sector')\n",
    "#df.to_csv('fortune_500_h1_cleaned.csv', index=False)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Looking for answers in data\n",
    "\n",
    "Now that the data has been prepared we can dive right in.\n",
    "Without writing much code or doing any math we may get some insights already"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1: Print - Probing for interesting values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the smallest/largest font size used on all the pages?\n",
    "print( 'Smallest Font Size:', df['font-size'].min() )\n",
    "print( 'Largest Font Size:', df['font-size'].max() )\n",
    "print( 'Mean Font Size:', round( df['font-size'].mean(), 1 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or just simply call describe to get min, max and more values all at once\n",
    "df['font-size'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group and count all the sectors we have\n",
    "df['sector'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1: Plot - Probing for patterns and insights by plots\n",
    "Let's probe some more by visualizing some values and see if there are any patterns or revelations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pairplot \"font-size\", \"font-weight\" and \"sector-codes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# plot \"font-size\", \"font-weight\", \"sector-codes\" against each other\n",
    "pp = sns.pairplot(df[[\"font-size\", \"font-weight\", \"sector-codes\"]], diag_kind=\"kde\", height=5);\n",
    "\n",
    "for ax in pp.axes.flat:\n",
    "    ax.yaxis.set_tick_params(labelleft=True)\n",
    "    ax.xaxis.set_tick_params(labelleft=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the font sizes used in the different sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show distribution of font sizes for each sector as boxplot >> Food & Drug Store vs Telecommunications\n",
    "outlier_style = dict(markerfacecolor='0.75', markersize=5, linestyle='none')\n",
    "sns.set(style=\"whitegrid\", rc={'figure.figsize':(20,17)})\n",
    "ax = sns.boxplot(x=\"font-size\", y=\"sector\", data=df, orient=\"h\", flierprops=outlier_style)\n",
    "ax = sns.stripplot(x=\"font-size\", y=\"sector\", data=df, orient=\"h\", size=3, jitter=True, color=\"#555555\")\n",
    "ax.tick_params(labelsize=20)\n",
    "ax.set(xlabel='', ylabel='');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the colors used in the different sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all the H1 colors of all sectors. >> No love for pink and purple?\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='polar')\n",
    "ax.scatter(x=df['h'] * 2 * np.pi, y=df['s'], c=df[\"hex\"], s=20 + (df['v']) * 150, alpha=0.75, edgecolors='black')\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_ylim([0, 1.1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the colors used in every individual sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all the H1 colors but for each sector independently\n",
    "sectors = df['sector'].unique()\n",
    "\n",
    "fig, axs = plt.subplots(7, 3, figsize=(20,20), subplot_kw=dict(polar=True))\n",
    "axs = np.reshape(axs, len(sectors))\n",
    "\n",
    "for i in range(len(sectors)):\n",
    "    c = df[ df['sector'] == sectors[i] ];\n",
    "    axs[i].scatter(x=c['h'] * 2 * np.pi, y=c['s'], c=c[\"hex\"], s=10 + (c['v']) * 100, alpha=0.75, edgecolors='black')\n",
    "    axs[i].set_title(sectors[i]);\n",
    "    axs[i].set_xticklabels([]);\n",
    "    axs[i].set_yticklabels([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3: Machine learning - Probing for patterns, insights, rules with statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick rows that are in the sector \"Apparel\" or \"Engineering & Construction\"\n",
    "X = df[(df['sector'] == \"Apparel\") | (df['sector'] == \"Engineering & Construction\")]\n",
    "\n",
    "# pick the properties we're interested in\n",
    "X = X[[\"r\", \"g\",  \"b\", \"sector-codes\"]]\n",
    "\n",
    "# normalize dataset for easier parameter selection\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# connectivity matrix for structured Ward clustering algorithm\n",
    "connectivity = kneighbors_graph(X, n_neighbors=10, include_self=False)\n",
    "# make connectivity symmetric\n",
    "connectivity = 0.5 * (connectivity + connectivity.T)\n",
    "\n",
    "num_clusters = 2\n",
    "\n",
    "# Let's use several clustering functions as we don't know yet which one is best for our data\n",
    "algorithms = (\n",
    "    ('MiniBatchKMeans', \n",
    "     cluster.MiniBatchKMeans(n_clusters=num_clusters)),\n",
    "    \n",
    "    ('MeanShift', \n",
    "     cluster.MeanShift(bandwidth=cluster.estimate_bandwidth(X, quantile=.3), bin_seeding=True)),\n",
    "    \n",
    "    ('SpectralClustering', \n",
    "     cluster.SpectralClustering(n_clusters=num_clusters, eigen_solver='arpack', affinity=\"nearest_neighbors\")),\n",
    "    \n",
    "    ('AgglomerativeClustering', \n",
    "     cluster.AgglomerativeClustering(n_clusters=num_clusters, linkage='ward', connectivity=connectivity)),\n",
    "    \n",
    "    ('Birch', \n",
    "     cluster.Birch(n_clusters=num_clusters)),\n",
    "    \n",
    "    ('GaussianMixture',\n",
    "    mixture.GaussianMixture(n_components=num_clusters, covariance_type='full'))\n",
    ")\n",
    "\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "plt.subplots_adjust(left=.02, right=.98, bottom=.01, top=.96, wspace=.1, hspace=.1)\n",
    "\n",
    "cluster_colors = np.hstack([np.array([c for c in 'bgrcmykbgrcmyk'])] * 20)\n",
    "\n",
    "for i in range(len(algorithms)):\n",
    "    (name, algo) = algorithms[i]\n",
    "    \n",
    "    algo.fit(X)\n",
    "    y_pred = algo.labels_.astype(np.int) if hasattr(algo, 'labels_') else algo.predict(X)\n",
    "    \n",
    "    plt.subplot(1, len(algorithms), i+1)\n",
    "    plt.title(name, size=14)\n",
    "    plt.scatter(X[:, 0], X[:, 1], s=100, color=cluster_colors[y_pred], edgecolors='white')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "05.07-Support-Vector-Machines.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
